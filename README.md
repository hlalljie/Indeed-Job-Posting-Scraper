# My-Indeed-AI
An expirement in using AI to filter job posts. 

## The current processes consists of:
### 1. Retrieve job posting data from Indeed
Through use of Selenium and Beautiful Soup, data is fetched from Indeed based on urls. Currently the data retrieved includes Job ID, Job Title, Company Name, Location, and Job Link. The inputs needed are a link to a search from Indeed and a file location for the output data. It outputs all of the data for every page of the search to a csv. This takes about a second or about 6 minutes for the 4 search links I provided, amounting to over 1000 posts. Note that other info sunch as Job pay will need to be retrieved from the Job link in a later iteration.
### 2. Cleaning and formating job data into a usable format for an LLM
Because Indeed provides multiple links to the same post, it was important to filter all of the results by unique Job ID. It was also important to insure that all of the data was being correctly read and formatted which provided some challenge.
### 3. Annototate Data for the LLM
After finding the unique IDs all of the data needed to be annotated. On the first iteration I rated only the title from 1-10 based on how likely I would be to apply to the position. My goal for the first iteration was to check the coorelation between amount of data per data point and the effectiveness of Brain.js's LLM. Currently the LLM has only used titles, but the data gathered will be compared to runs with ratings based on all of the information mentioned above. After trimming the dataset to only uniques ids, it contained 223 datapoints.
### 4. Train and Test the LLM using the Data
To train and test the model, the dataset was randomized and split into 80% (179) training points and 20%(44) test points. For each ran test the data was re-randomized and the model was retrained. Brain.js took a little over 2 hours for each training, with test time and other processes taking a negligable amount of time in comparison. From here the results were output into a CSV to be analyzed. For the first iteration 5 test were conducted on different randomized subsets of the same 223 data points.

### 5. Generating Statistics
On this first iteration the data required some cleaning as the AI model contained a small amount of junk data and output all of it's ratings as Strings. To better understand the data, a new csv was created that contained the difference between the actual rating and the Brain.js rating as well as the other data gathered before. Another csv was created for the entire test that included statistics for each sheet. This includes the Mean and Median for the real ratings, Brain.js ratings and the rating difference, the IQR, number of outliers, and Standard Devation for the real and Brain.js ratings, and the amount of correct guesses and junk data generated by the Brain.js model. 

### 6. Initial Analysis
Looking at the data, the Brain.js model tended to make safe estimates, sticking very close to the median value when choosing it's guesses. It had some success with common job titles, but overall missed more than it guessed correctly. Because it's guesses were close to the median, it failed to find outliers. Since finding outliers in order to filter bad jobs out and push good jobs to the top of my list was the goal, this iteration failed miserably. In order to improve on this model, I had planned to give the model more data per dat point (including company name, and location), but I would guess that this model will not perform any better, and might become confused if given more data per data point. I think the biggest imporvement to be made are in the amount of data, so it can see more outliers per test set, and in creating a custom model that is more specilized to finding outliers in a dataset.

### 7. Data Visualization
Data visualization in Seaborn to come, stay tuned!
